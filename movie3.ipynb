{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c11732c-283a-4948-9176-5200b20da0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tmdbsimple\n",
      "  Downloading tmdbsimple-2.9.1-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tmdbsimple) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->tmdbsimple) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->tmdbsimple) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->tmdbsimple) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->tmdbsimple) (2024.2.2)\n",
      "Installing collected packages: tmdbsimple\n",
      "Successfully installed tmdbsimple-2.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tmdbsimple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ecc9f7-6b56-45e6-b138-529b6fb1ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY = 'e4d3e8d00ed7332a43f7ce98098aaf27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc9ec6a-0121-4286-b162-f093546b17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "tmdb.REQUESTS_SESSION = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f11f76-5c72-4df5-8e5c-bc8a2555c627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Talk to Her'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = tmdb.Movies(64)\n",
    "response = movie.info()\n",
    "movie.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a36c14-ceda-4f02-86fc-156800f66f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n"
     ]
    }
   ],
   "source": [
    " response = movie.releases()\n",
    "for c in movie.countries:\n",
    "        if c['iso_3166_1'] == 'US':\n",
    "             print(c['certification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664a36c0-4acd-4ac8-b37b-67e58fac640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bourne Identity 2501 2002-06-14 64.391\n",
      "The Bourne Ultimatum 2503 2007-08-03 62.585\n",
      "The Bourne Supremacy 2502 2004-07-23 37.359\n",
      "The Bourne Legacy 49040 2012-08-08 48.241\n",
      "The Bourne Identity 895795 1988-05-08 4.607\n",
      "Matthew Bourne's The Red Shoes 748635 2020-09-30 1.004\n",
      "Matthew Bourne: The Nutcracker 1036829  0.36\n",
      "Matthew Bourne's The Car Man 702641 2016-03-13 0.84\n",
      "Bette Bourne: It Goes with the Shoes 179304 2013-03-21 0.593\n",
      "AVP The Monster Hydro Cup Day 2-1: Men’s Semi-Final 1 - Dalhausser and Lucena vs Tr. Crabb and Bourne 728042 2020-07-19 0.593\n",
      "Dancing Bournonville 390459 1979-01-01 0.84\n",
      "Bourn 744344 2020-09-25 0.908\n"
     ]
    }
   ],
   "source": [
    "search = tmdb.Search()\n",
    "response = search.movie(query='The Bourne')\n",
    "for s in search.results:\n",
    "    print(s['title'], s['id'], s['release_date'], s['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f14d9c-9079-48d9-aca4-db0130ce5293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608695"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    >>> identity = tmdb.Movies(2501)\n",
    "    >>> response = identity.info()\n",
    "    >>> identity.budget, identity.runtime\n",
    "    (60000000, 119)\n",
    "    >>> int(identity.budget/identity.runtime)\n",
    "    504201\n",
    "    >>> supremacy = tmdb.Movies(2502)\n",
    "    >>> response = supremacy.info()\n",
    "    >>> supremacy.budget, supremacy.runtime\n",
    "    (75000000, 108)\n",
    "    >>> int(supremacy.budget/supremacy.runtime)\n",
    "    694444\n",
    "    >>> ultimatum = tmdb.Movies(2503)\n",
    "    >>> response = ultimatum.info()\n",
    "    >>> ultimatum.budget, ultimatum.runtime\n",
    "    (70000000, 115)\n",
    "    >>> int(ultimatum.budget/ultimatum.runtime)\n",
    "    608695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58570280-da2a-4fbc-9003-09c57b83af27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " response = tmdb.Movies(603).info()\n",
    " response['budget']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "badbc95b-bf88-47e7-b478-b8d83de2f4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_31804\\3874403701.py:17: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_31804\\3874403701.py:19: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# List of file paths\n",
    "file_paths = ['Desktop/Project2/data1.tsv', 'Desktop/Project2/data.tsv', 'Desktop/Project2/title-akas-us-only.csv']\n",
    "\n",
    "# Connect to SQLite database (or create one if it doesn't exist)\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Function to load CSV or TSV files into SQLite tables\n",
    "def load_file_into_sqlite(file_path, table_name, delimiter=','):\n",
    "    # Read CSV or TSV file into DataFrame\n",
    "    if delimiter == ',':\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif delimiter == '\\t':\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "    else:\n",
    "        raise ValueError(\"Delimiter must be ',' or '\\t'\")\n",
    "    \n",
    "    # Write DataFrame to SQLite table\n",
    "    df.to_sql(table_name, conn, index=False, if_exists='replace')\n",
    "\n",
    "# Load CSV files into SQLite tables\n",
    "csv_files = [('Desktop/Project2/title-akas-us-only.csv', 'table1')]  \n",
    "\n",
    "for csv_file, table_name in csv_files:\n",
    "    load_file_into_sqlite(csv_file, table_name)\n",
    "\n",
    "# Load TSV files into SQLite tables\n",
    "tsv_files = [('Desktop/Project2/data1.tsv', 'table2'), ('Desktop/Project2/data.tsv', 'table3')]  \n",
    "\n",
    "for tsv_file, table_name in tsv_files:\n",
    "    load_file_into_sqlite(tsv_file, table_name, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0592dc4-55c7-4607-98b1-7cc190bc4a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie data for 2001 saved as movie_data_2001.csv.gz!\n",
      "Movie data for 2002 saved as movie_data_2002.csv.gz!\n"
     ]
    }
   ],
   "source": [
    "import tmdbsimple as tmdb\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# Set your TMDb API key\n",
    "tmdb.API_KEY = 'e4d3e8d00ed7332a43f7ce98098aaf27'\n",
    "\n",
    "# Function to fetch movie data\n",
    "# Function to fetch movie data\n",
    "def fetch_movie_data(start_year, end_year):\n",
    "    all_movies = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        page = 1\n",
    "        while True:\n",
    "            response = tmdb.Discover().movie(page=page, certification_country='US', certification_lte='R', sort_by='popularity.desc', release_date_gte=f'{year}-01-01', release_date_lte=f'{year}-12-31')\n",
    "            if 'results' in response:\n",
    "                for movie in response['results']:\n",
    "                    movie_info = extract_movie_info(movie)\n",
    "                    movie_info['Release_Year'] = year  # Add release year to movie info\n",
    "                    all_movies.append(movie_info)\n",
    "                if page < response['total_pages']:\n",
    "                    page += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    return all_movies\n",
    "\n",
    "# Function to extract required information from movie data\n",
    "def extract_movie_info(movie):\n",
    "    title = movie.get('title', None)\n",
    "    budget = movie.get('budget', None)\n",
    "    revenue = movie.get('revenue', None)\n",
    "    certification = movie.get('release_dates', {}).get('results', [{}])[0].get('certification', None)\n",
    "    return {\n",
    "        'Title': title,\n",
    "        'Budget': budget,\n",
    "        'Revenue': revenue,\n",
    "        'Certification': certification\n",
    "    }\n",
    "\n",
    "# Main function to fetch and process movie data\n",
    "def main(start_year, end_year):\n",
    "    movie_data = fetch_movie_data(start_year, end_year)\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        year_movies = [movie for movie in movie_data if movie['Release_Year'] == year]\n",
    "        df = pd.DataFrame(year_movies)\n",
    "        file_name = f'movie_data_{year}.csv.gz'\n",
    "        with gzip.open(file_name, 'wt', encoding='utf-8') as f:\n",
    "            df.to_csv(f, index=False)\n",
    "        print(f'Movie data for {year} saved as {file_name}!')\n",
    "\n",
    "# Specify the range of years\n",
    "start_year = 2001\n",
    "end_year = 2002\n",
    "\n",
    "# Fetch and process movie data\n",
    "main(start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c11c63a-7243-4b6a-941b-9a1813699307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Avengers data: {'Title': 'The Avengers', 'Budget': 220000000, 'Revenue': 1518815515, 'Certification': None}\n",
      "The Notebook data: {'Title': 'The Notebook', 'Budget': 29000000, 'Revenue': 115600000, 'Certification': None}\n"
     ]
    }
   ],
   "source": [
    "def fetch_movie_data(tmdb_id):\n",
    "    try:\n",
    "        movie = tmdb.Movies(tmdb_id)\n",
    "        response = movie.info()\n",
    "        # Extract relevant information from the response\n",
    "        title = response.get('title', None)\n",
    "        budget = response.get('budget', None)\n",
    "        revenue = response.get('revenue', None)\n",
    "        certification = response.get('release_dates', {}).get('results', [{}])[0].get('certification', None)\n",
    "        return {\n",
    "            'Title': title,\n",
    "            'Budget': budget,\n",
    "            'Revenue': revenue,\n",
    "            'Certification': certification\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching movie data for TMDb ID {tmdb_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function for \"The Avengers\" and \"The Notebook\" TMDb IDs\n",
    "avengers_id = 24428  # TMDb ID for The Avengers\n",
    "notebook_id = 11036  # TMDb ID for The Notebook\n",
    "\n",
    "avengers_data = fetch_movie_data(avengers_id)\n",
    "notebook_data = fetch_movie_data(notebook_id)\n",
    "\n",
    "print(\"The Avengers data:\", avengers_data)\n",
    "print(\"The Notebook data:\", notebook_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bd5dcd2-e2a9-4429-94b0-6676c5245baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a movie object using the .Movies function from tmdb\n",
    "movie = tmdb.Movies(603)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fe6b8cd-ee56-4799-b476-22cfb9476eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adult': False, 'backdrop_path': '/icmmSD4vTTDKOq2vvdulafOGw93.jpg', 'belongs_to_collection': {'id': 2344, 'name': 'The Matrix Collection', 'poster_path': '/bV9qTVHTVf0gkW0j7p7M0ILD4pG.jpg', 'backdrop_path': '/bRm2DEgUiYciDw3myHuYFInD7la.jpg'}, 'budget': 63000000, 'genres': [{'id': 28, 'name': 'Action'}, {'id': 878, 'name': 'Science Fiction'}], 'homepage': 'http://www.warnerbros.com/matrix', 'id': 603, 'imdb_id': 'tt0133093', 'origin_country': ['US'], 'original_language': 'en', 'original_title': 'The Matrix', 'overview': 'Set in the 22nd century, The Matrix tells the story of a computer hacker who joins a group of underground insurgents fighting the vast and powerful computers who now rule the earth.', 'popularity': 480.776, 'poster_path': '/f89U3ADr1oiB1s9GkdPOEpXUk5H.jpg', 'production_companies': [{'id': 79, 'logo_path': '/at4uYdwAAgNRKhZuuFX8ShKSybw.png', 'name': 'Village Roadshow Pictures', 'origin_country': 'US'}, {'id': 372, 'logo_path': None, 'name': 'Groucho II Film Partnership', 'origin_country': ''}, {'id': 1885, 'logo_path': '/xlvoOZr4s1PygosrwZyolIFe5xs.png', 'name': 'Silver Pictures', 'origin_country': 'US'}, {'id': 174, 'logo_path': '/zhD3hhtKB5qyv7ZeL4uLpNxgMVU.png', 'name': 'Warner Bros. Pictures', 'origin_country': 'US'}], 'production_countries': [{'iso_3166_1': 'US', 'name': 'United States of America'}], 'release_date': '1999-03-31', 'revenue': 463517383, 'runtime': 136, 'spoken_languages': [{'english_name': 'English', 'iso_639_1': 'en', 'name': 'English'}], 'status': 'Released', 'tagline': 'Believe the unbelievable.', 'title': 'The Matrix', 'video': False, 'vote_average': 8.215, 'vote_count': 24867}\n"
     ]
    }
   ],
   "source": [
    "info = movie.info()\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad688ebd-9bfb-4477-beef-36f755a20765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39e4d38e-62b1-4a08-a597-7c0eaa3c9e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463517383"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59350e27-07a5-40ce-a5be-1d1e5d0f4e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tt0133093'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['imdb_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10fb06ca-29b6-4767-bbbf-8745dc8db023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "# example from package README\n",
    "# source = https://github.com/celiao/tmdbsimple\n",
    "releases = movie.releases()\n",
    "for c in releases['countries']:\n",
    "    if c['iso_3166_1'] == 'US':\n",
    "        print(c['certification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6352a116-0e9c-4fe6-b90e-298dd94d9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_31804\\2434500045.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Desktop/Project2/data1.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Desktop/Project2/data1.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2d66320-34b4-4e95-ad3f-507357564c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>4</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy,Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "  isAdult startYear endYear runtimeMinutes                    genres  \n",
       "0       0      1894      \\N              1         Documentary,Short  \n",
       "1       0      1892      \\N              5           Animation,Short  \n",
       "2       0      1892      \\N              4  Animation,Comedy,Romance  \n",
       "3       0      1892      \\N             12           Animation,Short  \n",
       "4       0      1893      \\N              1              Comedy,Short  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "114074eb-7210-4240-88ec-b53e316cc661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n"
     ]
    }
   ],
   "source": [
    "# Define the range of years you wish to retrieve\n",
    "start_year = 2000\n",
    "end_year = 2020  # Adjust this to the current year or any other end year you prefer\n",
    "\n",
    "# Create a list of years from start_year to end_year (inclusive)\n",
    "years_list = list(range(start_year, end_year + 1))\n",
    "\n",
    "# Print the list of years\n",
    "print(years_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "565fced8-705b-4c5a-9727-24469a62148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9b8701c38d4ac78639a98091b7e461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing years:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2000 and saving to data_2000.json\n",
      "Processing data for year 2001 and saving to data_2001.json\n",
      "Processing data for year 2002 and saving to data_2002.json\n",
      "Processing data for year 2003 and saving to data_2003.json\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# List of years\n",
    "years_list = [2000, 2001, 2002, 2003]  # Example list of years\n",
    "\n",
    "# Outer loop with progress bar\n",
    "for year in tqdm(years_list, desc=\"Processing years\"):\n",
    "    # Define JSON filename with the year\n",
    "    json_filename = f\"data_{year}.json\"\n",
    "\n",
    "    # Your code to process data for the current year and save results to json_filename\n",
    "    # Example: fetch data for the current year and save it to json_filename\n",
    "    # fetch_data_for_year(year)\n",
    "    # save_results_to_json(results, json_filename)\n",
    "\n",
    "    # Print progress information\n",
    "    print(f\"Processing data for year {year} and saving to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6ffa574-ffe9-4c70-87ec-0cd69f88091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 4004.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file for year 2000 already exists: data_2000.json\n",
      "Processing data for year 2000 and saving to data_2000.json\n",
      "JSON file for year 2001 already exists: data_2001.json\n",
      "Processing data for year 2001 and saving to data_2001.json\n",
      "JSON file for year 2002 already exists: data_2002.json\n",
      "Processing data for year 2002 and saving to data_2002.json\n",
      "JSON file for year 2003 already exists: data_2003.json\n",
      "Processing data for year 2003 and saving to data_2003.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Outer loop with progress bar\n",
    "for year in tqdm(years_list, desc=\"Processing years\"):\n",
    "    # Define JSON filename with the year\n",
    "    json_filename = f\"data_{year}.json\"\n",
    "\n",
    "    # Check if the JSON file exists\n",
    "    if not os.path.exists(json_filename):\n",
    "        # If it doesn't exist, create an empty JSON file\n",
    "        with open(json_filename, 'w') as f:\n",
    "            # Write an empty dictionary\n",
    "            json.dump({}, f)\n",
    "        print(f\"Created JSON file for year {year}: {json_filename}\")\n",
    "    else:\n",
    "        # If it exists, print a message\n",
    "        print(f\"JSON file for year {year} already exists: {json_filename}\")\n",
    "\n",
    "    # Your code to process data for the current year and save results to json_filename\n",
    "    # Example: fetch data for the current year and save it to json_filename\n",
    "    # fetch_data_for_year(year)\n",
    "    # save_results_to_json(results, json_filename)\n",
    "\n",
    "    # Print progress information\n",
    "    print(f\"Processing data for year {year} and saving to {json_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8f6bdc0-a400-4830-856f-e797592b417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1332.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file for year 2000 is empty.\n",
      "Error reading JSON file for year 2001: If using all scalar values, you must pass an index\n",
      "Error reading JSON file for year 2002: If using all scalar values, you must pass an index\n",
      "Error reading JSON file for year 2003: If using all scalar values, you must pass an index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming you have loaded the IMDb title basics data into a DataFrame named df\n",
    "# and you have a list of years named years_list\n",
    "\n",
    "# Outer loop with progress bar\n",
    "for year in tqdm(years_list, desc=\"Processing years\"):\n",
    "    # Define JSON filename with the year\n",
    "    json_filename = f\"data_{year}.json\"\n",
    "\n",
    "    # Check if the JSON file exists\n",
    "    if os.path.exists(json_filename):\n",
    "        try:\n",
    "            # Load the contents of the JSON file\n",
    "            with open(json_filename, 'r') as file:\n",
    "                json_data = file.read()\n",
    "                if json_data.strip():  # Check if JSON data is not empty\n",
    "                    json_data = pd.read_json(json_data, orient='records')\n",
    "                    # Filter the data for the selected year\n",
    "                    selected_year_data = df[df['startYear'] == year]\n",
    "\n",
    "                    # Extract movie IDs for the selected year\n",
    "                    movie_ids = selected_year_data[selected_year_data['titleType'] == 'movie']['tconst'].tolist()\n",
    "\n",
    "                    # Check for previously downloaded movie IDs and filter out duplicates\n",
    "                    existing_movie_ids = json_data['imdb_id'].tolist()\n",
    "                    movie_ids_to_get = [movie_id for movie_id in movie_ids if movie_id not in existing_movie_ids]\n",
    "\n",
    "                    # Save the final list of movie_ids_to_get without duplicates\n",
    "                    print(\"Final list of movie IDs to get:\", movie_ids_to_get)\n",
    "                else:\n",
    "                    print(f\"JSON file for year {year} is empty.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading JSON file for year {year}: {e}\")\n",
    "    else:\n",
    "        print(f\"JSON file for year {year} does not exist.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d8905b3-fd55-4bc1-845a-be779253b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years:   0%|                                                                          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing JSON file for year 2000: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years:  50%|█████████████████████████████████                                 | 2/4 [00:00<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing JSON file for year 2001: string indices must be integers, not 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years:  75%|█████████████████████████████████████████████████▌                | 3/4 [00:01<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing JSON file for year 2002: string indices must be integers, not 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing years: 100%|██████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing JSON file for year 2003: string indices must be integers, not 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Function to make API calls and extract results\n",
    "def fetch_results(movie_id):\n",
    "    # Your code to fetch results for a given movie ID\n",
    "    pass\n",
    "\n",
    "# Outer loop with progress bar\n",
    "for year in tqdm(years_list, desc=\"Processing years\"):\n",
    "    # Define JSON filename with the year\n",
    "    json_filename = f\"data_{year}.json\"\n",
    "\n",
    "    # Check if the JSON file exists\n",
    "    if os.path.exists(json_filename):\n",
    "        try:\n",
    "            # Load the contents of the JSON file\n",
    "            with open(json_filename, 'r') as file:\n",
    "                json_data = json.load(file)\n",
    "                \n",
    "            # Filter the data for the selected year\n",
    "            selected_year_data = df[df['startYear'] == year]\n",
    "\n",
    "            # Extract movie IDs for the selected year\n",
    "            movie_ids = selected_year_data[selected_year_data['titleType'] == 'movie']['tconst'].tolist()\n",
    "\n",
    "            # Check for previously downloaded movie IDs and filter out duplicates\n",
    "            existing_movie_ids = [entry['imdb_id'] for entry in json_data]\n",
    "            movie_ids_to_get = [movie_id for movie_id in movie_ids if movie_id not in existing_movie_ids]\n",
    "\n",
    "            # Inner loop for making API calls for each movie ID to get results\n",
    "            for movie_id in movie_ids_to_get:\n",
    "                # Make API call and extract results\n",
    "                results = fetch_results(movie_id)\n",
    "                \n",
    "                # Append new results to the list from the JSON file\n",
    "                json_data.append(results)\n",
    "\n",
    "            # Save the updated JSON file back to the disk\n",
    "            with open(json_filename, 'w') as file:\n",
    "                json.dump(json_data, file, indent=4)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing JSON file for year {year}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"JSON file for year {year} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802c32e-0f30-45c8-aeaf-e6eba6ec3088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
